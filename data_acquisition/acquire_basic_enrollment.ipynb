{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8139c74",
   "metadata": {},
   "source": [
    "# Todo\n",
    "* think about storing the data and all the data.... sqllite, HDF5, pickle, csv\n",
    "* better comments\n",
    "* once through to clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48246f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# gets rid of ssl errors\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba2fb4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import re\n",
    "\n",
    "# set this to the list of expected columns\n",
    "int64_columns = ['PKA', 'PKP', 'PKF', 'K4A', 'K4P', 'K4F', 'K5A', 'K5P', 'K5F',\n",
    "                 '001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
    "                 '010', '011', '012', 'school_year']\n",
    "string_columns = ['LEA Name', 'LEA Type', 'County', 'School Name', 'AUN', 'School Number']\n",
    "expected_columns = string_columns + int64_columns\n",
    "\n",
    "url = \"https://www.education.pa.gov/DataAndReporting/Enrollment/Pages/PublicSchEnrReports.aspx\"\n",
    "host = re.sub(r'(https*://[^/]+).*','\\\\1',url)\n",
    "req = Request(url)\n",
    "html_page = urlopen(req)\n",
    "\n",
    "soup = BeautifulSoup(html_page, \"html\")\n",
    "\n",
    "links = []\n",
    "for link in soup.findAll('a'):\n",
    "    links.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6422d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this filters down the list to just what we are looking for\n",
    "links = list( filter(lambda l: re.search(r'Enrollment%20Public%20Schools*%2020\\d\\d-\\d\\d\\.xlsx*$', str(l) ) , links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6062ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will put the host part of the URL back on the beginning of the link\n",
    "links = list(map( lambda l: host + l, links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9853816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will do the download, just pass it a sheet and URL or file name\n",
    "def download_excel(file,sheet,skiprows):\n",
    "        # download and read in the sheet\n",
    "        df = pd.DataFrame()\n",
    "        try:\n",
    "            df = pd.read_excel(file,\n",
    "                       sheet_name=sheet,\n",
    "                       skiprows=skiprows)\n",
    "        except:\n",
    "            print( 'Error: not able to download: ' + file )\n",
    "            \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "488cbaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds one giant dataframe\n",
    "df = pd.DataFrame()\n",
    "count=0\n",
    "for l in links: \n",
    "    if count < 120:\n",
    "        # find the start year from the URL\n",
    "        school_year = re.sub('^https.+(\\d\\d\\d\\d)-\\d\\d.xlsx*$','\\\\1',l)\n",
    "        #print( school_year + \": \" + l )\n",
    "\n",
    "        # download and read in the sheet\n",
    "        if int(school_year) >= 2011:\n",
    "            df1 = download_excel(l,'LEA and School', 4)\n",
    "        elif int(school_year) == 2010:\n",
    "            df1 = download_excel(l,'School', 4)\n",
    "        elif int(school_year) == 2009:\n",
    "            df1 = download_excel(l,'School - Data File', 4)\n",
    "        elif int(school_year) == 2008:\n",
    "            df1 = download_excel(l,'School - Datafile', 4)\n",
    "        elif int(school_year) == 2007:\n",
    "            df1 = download_excel(l,'LEA - Data File', 6)\n",
    "        elif int(school_year) == 2006:\n",
    "            df1 = download_excel(l,'School Enrollments', 1)\n",
    "        elif int(school_year) == 2005:\n",
    "            df1 = download_excel(l,'School Enrollments by LEA', 2)\n",
    "        else:     \n",
    "            df1 = download_excel(l,'School Enrollments', 2)\n",
    "\n",
    "\n",
    "        # 2006 has some bad columns in it. this makes them conform\n",
    "        col = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
    "        for c in col:\n",
    "            if c in df1.columns:\n",
    "                nc = \"00\" + str(c)\n",
    "                nc = nc[-3:]\n",
    "                df1.rename(columns={c: nc}, inplace=True)\n",
    "        \n",
    "        # more 2006. They don't break K into AM, PM, Full. So put all numbers in AM\n",
    "        if 'PreK' in df1.columns:\n",
    "            df1.rename(columns={\"PreK\": \"PKA\"}, inplace=True)\n",
    "        if 'K4' in df1.columns:\n",
    "            df1.rename(columns={\"K4\": \"K4A\"}, inplace=True)\n",
    "        if 'K5' in df1.columns:\n",
    "            df1.rename(columns={\"K5\": \"K5A\"}, inplace=True)\n",
    "        \n",
    "        # 2006 uses county name instead of county\n",
    "        if \"County Name\" in df1.columns:\n",
    "            df1.rename(columns={\"County Name\": \"County\"}, inplace=True)\n",
    "        \n",
    "        # 2011 has a 7 as a column name. renaming that. its an int 7 not a string 7. \n",
    "        if 7 in df1.columns:\n",
    "            df1.rename(columns={7: \"007\"}, inplace=True)\n",
    "\n",
    "        # add LEA Type by using the end of the LEA Name. For example Avon Grove School\n",
    "        # district would be \"Avon Grove SD\". So pulling off the right most string without \n",
    "        # a space will get me the LEA Type\n",
    "        if 'LEA Type' not in df1.columns:\n",
    "            pd.Series(df1['LEA Name'], dtype=\"string\") # doing this now because in 2005 its a strange data type\n",
    "            df1['LEA Type'] = df['LEA Name'].apply(lambda x: re.sub(' (\\S+)$','\\\\1',x))       \n",
    "\n",
    "        # add in school year\n",
    "        df1['school_year'] = school_year\n",
    "         \n",
    "        # get rid of any row where school number isn't a number\n",
    "        if 'School Number' in df1.columns:\n",
    "            df1['School Number'] = pd.Series(df1['School Number'], dtype=\"string\")\n",
    "            df1 = df1[df1['School Number'].str.contains('^[\\d\\.]+$', regex= True, na=False)]\n",
    "        \n",
    "        # fix datatypes\n",
    "        for col in int64_columns:\n",
    "            # if doesn't exist create it\n",
    "            if col not in df1.columns:\n",
    "                df1[col] = np.nan\n",
    "            df1[col] = pd.Series(df1[col], dtype=\"Int64\")   \n",
    "                \n",
    "        for col in string_columns:\n",
    "            # if doesn't exist create it\n",
    "            if col not in df1.columns:\n",
    "                df1[col] = np.nan\n",
    "            df1[col] = pd.Series(df1[col], dtype=\"string\") \n",
    "\n",
    "        # some of the older files have pivot table looking reports. Where say the \n",
    "        # county is in row 1 with 200 schools, and the next 199 rows they don't\n",
    "        # repeat the county. So this fills in County and the School District or \n",
    "        # LEA Name\n",
    "        fields = ['County', 'LEA Name', 'AUN']\n",
    "        for f in fields:\n",
    "            field = ''\n",
    "            for i, row in df1.iterrows():\n",
    "                if not pd.isna(df1.at[i,f]):\n",
    "                    field = df1.at[i,f]\n",
    "                else:\n",
    "                    df1.at[i,f] = field\n",
    "            \n",
    "        # this drops un-used columns. compares retrieved col to expected ones\n",
    "        for col in df1.columns.difference(expected_columns):\n",
    "            if col in df1.columns:\n",
    "                df1.drop(columns=[col], inplace=True)\n",
    "\n",
    "        # drops any rows where LEA Name ends in Total\n",
    "        df1 = df1[~df1['LEA Name'].str.contains('^.*Total$', regex= True, na=False)]\n",
    "        \n",
    "        # concat the newly downloaded df onto the larger one\n",
    "        df = pd.concat([df, df1],\n",
    "                       ignore_index=True,)\n",
    "    count = count + 1\n",
    "\n",
    "# convert header names to strings\n",
    "df.columns = df.columns.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0fde44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick better names\n",
    "df.columns = [column.strip().replace(' ', '_').lower() for column in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61b7eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill in blank aun. years 2006 and earlier don't have aun. So by lea_name grab first aun going\n",
    "## back in time. and use that to fill in the blanks\n",
    "\n",
    "# keep the first aun we find for each SD\n",
    "df_aun = df.drop_duplicates(subset='lea_name', keep=\"first\")[['aun', 'lea_name']]\n",
    "\n",
    "# rename aun column\n",
    "df_aun.rename(columns={\"aun\": \"aun_fix\"}, inplace=True)\n",
    "\n",
    "# join on lea_name\n",
    "df = df.join(df_aun.set_index('lea_name'), on='lea_name')\n",
    "\n",
    "# only if aun is empty put in the joined aun_fix\n",
    "df['aun'] = df.apply(lambda x: x['aun_fix'] if x['aun']=='' else x['aun'], axis=1)\n",
    "\n",
    "# drop fix columns\n",
    "df.drop(columns=['aun_fix'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5dd86db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt to long format\n",
    "df = pd.melt(df, id_vars=['aun', 'lea_name', 'lea_type', 'county', 'school_number', 'school_name', 'school_year'],\n",
    "        var_name='grade', value_name='enrollment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a54ec2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make more efficient change data type on columns with lots of repeating values to category\n",
    "for col in df.columns:\n",
    "    if col != 'enrollment':\n",
    "        df[col] = pd.Series(df[col], dtype=\"category\") \n",
    "    else:\n",
    "        df[col] = pd.Series(df[col], dtype=\"Int64\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "766031ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data out for another script to consume\n",
    "df.to_pickle(\"../data/basic_enrollment.pkl.bz2\", compression='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77e65faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['aun', 'lea_name', 'lea_type', 'county', 'school_number', 'school_name',\n",
       "       'school_year', 'grade', 'enrollment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3aa1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df[['AUN', 'LEA Name']]\n",
    "#df2.drop_duplicates(keep='first')\n",
    "#df2 = df2.drop_duplicates(subset='LEA Name', keep=\"first\")\n",
    "#df2\n",
    "#df.groupby(['aun', 'lea_name']).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
