{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8139c74",
   "metadata": {},
   "source": [
    "# Todo\n",
    "* better comments\n",
    "* once through to clean up\n",
    "* 2004, 2005, 2006 are commented out due to quality issues. mostly around lea_type and aun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48246f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.parse\n",
    "import os\n",
    "import requests\n",
    "import sqlite3 as db\n",
    "\n",
    "# gets rid of ssl errors\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2fb4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import re\n",
    "\n",
    "# set this to the list of expected columns\n",
    "int_columns = ['PKA', 'PKP', 'PKF', 'K4A', 'K4P', 'K4F', 'K5A', 'K5P', 'K5F',\n",
    "                 '001', '002', '003', '004', '005', '006', '007', '008', '009',\n",
    "                 '010', '011', '012', 'school_year']\n",
    "string_columns = ['LEA Name', 'LEA Type', 'County', 'School Name', 'AUN', 'School Number']\n",
    "expected_columns = string_columns + int_columns\n",
    "\n",
    "url = \"https://www.education.pa.gov/DataAndReporting/Enrollment/Pages/PublicSchEnrReports.aspx\"\n",
    "host = re.sub(r'(https*://[^/]+).*','\\\\1',url)\n",
    "req = Request(url)\n",
    "html_page = urlopen(req)\n",
    "\n",
    "soup = BeautifulSoup(html_page, \"html\")\n",
    "\n",
    "links = []\n",
    "for link in soup.findAll('a'):\n",
    "    links.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6422d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this filters down the list to just what we are looking for\n",
    "links = list( filter(lambda l: re.search(r'Enrollment%20Public%20Schools*%2020\\d\\d-\\d\\d\\.xlsx*$', str(l) ) , links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6062ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will put the host part of the URL back on the beginning of the link\n",
    "links = list(map( lambda l: host + l, links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9853816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will download a file if local cache doesn't exist and then return local file name\n",
    "def cache_url(file):\n",
    "\n",
    "    # set directory base and create if doesn't exist\n",
    "    directory='../data/raw/basic_enrollment/'\n",
    "    try:\n",
    "        os.stat(directory)\n",
    "    except:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # decode the URL name. then split on /. and grab last item in list which will be the file name\n",
    "    dec=urllib.parse.unquote( file )\n",
    "    file_list=dec.split('/')\n",
    "    len_list=len(file_list)\n",
    "    cache_file=directory + file_list[len_list-1].lower().replace(' ', '_')\n",
    "\n",
    "    # see if file exists. if so use that. otherwise download it\n",
    "    if not os.path.exists( cache_file ):\n",
    "        print( 'caching file: ' + cache_file )\n",
    "        file_to_write = requests.get(file)\n",
    "        with open(cache_file, 'wb') as f:\n",
    "            f.write(file_to_write.content)\n",
    "        \n",
    "    return cache_file\n",
    "\n",
    "# this will do the download, just pass it a sheet and URL or file name\n",
    "def download_excel(file,sheet,skiprows):\n",
    "        # download and read in the sheet\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        # download, cache file, and return cached name\n",
    "        file=cache_url(file)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_excel(file,\n",
    "                       sheet_name=sheet,\n",
    "                       skiprows=skiprows)\n",
    "        except:\n",
    "            print( 'Error: not able to download: ' + file )\n",
    "            \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488cbaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds one giant dataframe\n",
    "df = pd.DataFrame()\n",
    "count=0\n",
    "for l in links: \n",
    "    if count < 120:\n",
    "        # find the start year from the URL\n",
    "        school_year = re.sub('^https.+(\\d\\d\\d\\d)-\\d\\d.xlsx*$','\\\\1',l)\n",
    "        #print( school_year + \": \" + l )\n",
    "\n",
    "        # download and read in the sheet\n",
    "        if int(school_year) >= 2011:\n",
    "            df1 = download_excel(l,'LEA and School', 4)\n",
    "        elif int(school_year) == 2010:\n",
    "            df1 = download_excel(l,'School', 4)\n",
    "        elif int(school_year) == 2009:\n",
    "            df1 = download_excel(l,'School - Data File', 4)\n",
    "        elif int(school_year) == 2008:\n",
    "            df1 = download_excel(l,'School - Datafile', 4)\n",
    "        elif int(school_year) == 2007:\n",
    "            df1 = download_excel(l,'LEA - Data File', 6)\n",
    "        # these are commented out as more work is required to clean up the data\n",
    "        #elif int(school_year) == 2006:\n",
    "        #    df1 = download_excel(l,'School Enrollments', 1)\n",
    "        #elif int(school_year) == 2005:\n",
    "        #    df1 = download_excel(l,'School Enrollments by LEA', 2)\n",
    "        #elif int(school_year) == 2004:\n",
    "        #    df1 = download_excel(l,'School Enrollments', 2)\n",
    "\n",
    "\n",
    "        # 2006 has some bad columns in it. this makes them conform\n",
    "        col = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
    "        for c in col:\n",
    "            if c in df1.columns:\n",
    "                nc = \"00\" + str(c)\n",
    "                nc = nc[-3:]\n",
    "                df1.rename(columns={c: nc}, inplace=True)\n",
    "        \n",
    "        # more 2006. They don't break K into AM, PM, Full. So put all numbers in AM\n",
    "        if 'PreK' in df1.columns:\n",
    "            df1.rename(columns={\"PreK\": \"PKA\"}, inplace=True)\n",
    "        if 'K4' in df1.columns:\n",
    "            df1.rename(columns={\"K4\": \"K4A\"}, inplace=True)\n",
    "        if 'K5' in df1.columns:\n",
    "            df1.rename(columns={\"K5\": \"K5A\"}, inplace=True)\n",
    "        \n",
    "        # 2006 uses county name instead of county\n",
    "        if \"County Name\" in df1.columns:\n",
    "            df1.rename(columns={\"County Name\": \"County\"}, inplace=True)\n",
    "        \n",
    "        # 2011 has a 7 as a column name. renaming that. its an int 7 not a string 7. \n",
    "        if 7 in df1.columns:\n",
    "            df1.rename(columns={7: \"007\"}, inplace=True)\n",
    "\n",
    "        # add LEA Type by using the end of the LEA Name. For example Avon Grove School\n",
    "        # district would be \"Avon Grove SD\". So pulling off the right most string without \n",
    "        # a space will get me the LEA Type\n",
    "        if 'LEA Type' not in df1.columns:\n",
    "            pd.Series(df1['LEA Name'], dtype=\"string\") # doing this now because in 2005 its a strange data type\n",
    "            df1['LEA Type'] = df['LEA Name'].apply(lambda x: re.sub(' (\\S+)$','\\\\1',x))       \n",
    "\n",
    "        # add in school year\n",
    "        df1['school_year'] = school_year\n",
    "         \n",
    "        # get rid of any row where school number isn't a number\n",
    "        if 'School Number' in df1.columns:\n",
    "            df1['School Number'] = pd.Series(df1['School Number'], dtype=\"string\")\n",
    "            df1 = df1[df1['School Number'].str.contains('^[\\d\\.]+$', regex= True, na=False)]\n",
    "        \n",
    "        # fix datatypes\n",
    "        for col in int_columns:\n",
    "            # if doesn't exist create it\n",
    "            if col not in df1.columns:\n",
    "                df1[col] = np.nan\n",
    "            df1[col] = pd.Series(df1[col], dtype=\"UInt16\")   \n",
    "                \n",
    "        for col in string_columns:\n",
    "            # if doesn't exist create it\n",
    "            if col not in df1.columns:\n",
    "                df1[col] = np.nan\n",
    "            df1[col] = pd.Series(df1[col], dtype=\"string\") \n",
    "\n",
    "        # some of the older files have pivot table looking reports. Where say the \n",
    "        # county is in row 1 with 200 schools, and the next 199 rows they don't\n",
    "        # repeat the county. So this fills in County and the School District or \n",
    "        # LEA Name\n",
    "        fields = ['County', 'LEA Name', 'AUN']\n",
    "        for f in fields:\n",
    "            field = ''\n",
    "            for i, row in df1.iterrows():\n",
    "                if not pd.isna(df1.at[i,f]):\n",
    "                    field = df1.at[i,f]\n",
    "                else:\n",
    "                    df1.at[i,f] = field\n",
    "            \n",
    "        # this drops un-used columns. compares retrieved col to expected ones\n",
    "        for col in df1.columns.difference(expected_columns):\n",
    "            if col in df1.columns:\n",
    "                df1.drop(columns=[col], inplace=True)\n",
    "\n",
    "        # drops any rows where LEA Name ends in Total\n",
    "        df1 = df1[~df1['LEA Name'].str.contains('^.*Total$', regex= True, na=False)]\n",
    "        \n",
    "        # concat the newly downloaded df onto the larger one\n",
    "        df = pd.concat([df, df1],\n",
    "                       ignore_index=True,)\n",
    "    count = count + 1\n",
    "\n",
    "# convert header names to strings\n",
    "df.columns = df.columns.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1414bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick better names\n",
    "df.columns = [column.strip().replace(' ', '_').lower() for column in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b516bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill in blank aun. years 2006 and earlier don't have aun. So by lea_name grab first aun going\n",
    "## back in time. and use that to fill in the blanks\n",
    "\n",
    "# keep the first aun we find for each SD\n",
    "df_aun = df.drop_duplicates(subset='lea_name', keep=\"first\")[['aun', 'lea_name']]\n",
    "\n",
    "# rename aun column\n",
    "df_aun.rename(columns={\"aun\": \"aun_fix\"}, inplace=True)\n",
    "\n",
    "# join on lea_name\n",
    "df = df.join(df_aun.set_index('lea_name'), on='lea_name')\n",
    "\n",
    "# only if aun is empty put in the joined aun_fix\n",
    "df['aun'] = df.apply(lambda x: x['aun_fix'] if x['aun']=='' else x['aun'], axis=1)\n",
    "\n",
    "# drop fix columns\n",
    "df.drop(columns=['aun_fix'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88746295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt to long format\n",
    "df = pd.melt(df, id_vars=['aun', 'lea_name', 'lea_type', 'county', 'school_number', 'school_name', 'school_year'],\n",
    "        var_name='grade', value_name='enrollment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d08ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make more efficient change data type on columns with lots of repeating values to category\n",
    "for col in df.columns:\n",
    "    if col != 'enrollment':\n",
    "        df[col] = pd.Series(df[col], dtype=\"category\") \n",
    "    else:\n",
    "        df[col] = pd.Series(df[col], dtype=\"UInt16\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "766031ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data out for another script to consume\n",
    "df.to_pickle(\"../data/basic_enrollment.pkl.bz2\", compression='infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a29709",
   "metadata": {},
   "source": [
    "## Below this will be putting summarized tables into sqlite3 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43fa79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DB file\n",
    "cnx = db.connect('../data/pde.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2e474cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lea_info table -> using most recent information about aun so to normalize throughout years\n",
    "desired_columns=['aun', 'lea_name', 'lea_type', 'county']                     # list of columns we want\n",
    "lea_info = df.sort_values(by = 'school_year', ascending = False)  # sort by school_year newest first. will grab most recent entry\n",
    "lea_info = lea_info[desired_columns]                              # throw out columns we don't want\n",
    "lea_info = lea_info.drop_duplicates(subset='aun', keep='first', inplace=False, ignore_index=True)\n",
    "lea_info = lea_info.set_index(['aun'])\n",
    "lea_info.to_sql(name='lea_info', con=cnx, if_exists='replace', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f062bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create school_into table -> using most recent information about school so to normalize throughout years\n",
    "desired_columns=['school_number', 'school_name', 'aun']              # list of columns we want\n",
    "school_info = df.sort_values(by = 'school_year', ascending = False)  # sort by school_year newest first. will grab most recent entry\n",
    "school_info = school_info[desired_columns]                           # throw out columns we don't want\n",
    "school_info = school_info.drop_duplicates(subset='school_number', keep='first', inplace=False, ignore_index=True)\n",
    "school_info = school_info.set_index(['school_number'])\n",
    "school_info.to_sql(name='school_info', con=cnx, if_exists='replace', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16ff0c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic_enrollment table\n",
    "desired_columns=['aun', 'school_number', 'school_year', 'grade', 'enrollment']    # list of columns we want\n",
    "basic_enrollment = df[desired_columns]                                            # throw out columns we don't want\n",
    "basic_enrollment = basic_enrollment.set_index(['aun', 'school_number', 'school_year', 'grade'])\n",
    "basic_enrollment.to_sql(name='basic_enrollment', con=cnx, if_exists='replace', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db0bc8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summarized lea enrollment\n",
    "lea_w_enrollment = pd.pivot_table(df,index=[\"aun\", \"school_year\"], values=[\"enrollment\"],aggfunc=np.sum, observed=True)\n",
    "lea_w_enrollment.to_sql(name='lea_w_enrollment', con=cnx, if_exists='replace', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5150297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summarized school enrollment\n",
    "school_w_enrollment = pd.pivot_table(df,index=[\"school_number\", \"school_year\"], values=[\"enrollment\"],aggfunc=np.sum, observed=True)\n",
    "school_w_enrollment.to_sql(name='school_w_enrollment', con=cnx, if_exists='replace', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f51c728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the database\n",
    "cnx.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
