{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8139c74",
   "metadata": {},
   "source": [
    "# Todo\n",
    "* More cleanup\n",
    "* Need to create a dataset with just basic district into so i can join on things like lea_type\n",
    "\n",
    "# Notes\n",
    "* This document has all the budget codes -> https://www.education.pa.gov/Documents/Teachers-Administrators/School%20Finances/Comptrollers%20Office/Chart%20of%20Accounts.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "48246f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import plotly.express as px\n",
    "#import plotly.io as pio\n",
    "import urllib.parse\n",
    "import os\n",
    "import requests\n",
    "import sqlite3 as db\n",
    "\n",
    "\n",
    "# gets rid of ssl errors\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba2fb4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import re\n",
    "\n",
    "\n",
    "url = \"https://www.education.pa.gov/Teachers%20-%20Administrators/School%20Finances/Finances/GFBData/Pages/default.aspx\"\n",
    "host = re.sub(r'(https*://[^/]+).*','\\\\1',url)\n",
    "req = Request(url)\n",
    "html_page = urlopen(req)\n",
    "\n",
    "soup = BeautifulSoup(html_page, \"html\")\n",
    "\n",
    "links = []\n",
    "for link in soup.findAll('a'):\n",
    "    links.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6422d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this filters down the list to just what we are looking for\n",
    "links = list( filter(lambda l: re.search(r'20\\d\\d-\\d\\dGFBData\\.xlsx$', str(l) ) , links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "526cf862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will put the host part of the URL back on the beginning of the link\n",
    "links = list(map( lambda l: host + l, links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9853816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will download a file if local cache doesn't exist and then return local file name\n",
    "def cache_url(file):\n",
    "\n",
    "    # set directory base and create if doesn't exist\n",
    "    directory='../data/raw/finance_expenses/'\n",
    "    try:\n",
    "        os.stat(directory)\n",
    "    except:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # decode the URL name. then split on /. and grab last item in list which will be the file name\n",
    "    dec=urllib.parse.unquote( file )\n",
    "    file_list=dec.split('/')\n",
    "    len_list=len(file_list)\n",
    "    cache_file=directory + file_list[len_list-1].lower().replace(' ', '_')\n",
    "\n",
    "    # see if file exists. if so use that. otherwise download it\n",
    "    if not os.path.exists( cache_file ):\n",
    "        print( 'caching file: ' + cache_file )\n",
    "        file_to_write = requests.get(file)\n",
    "        with open(cache_file, 'wb') as f:\n",
    "            f.write(file_to_write.content)\n",
    "        \n",
    "    return cache_file\n",
    "\n",
    "# this will do the download, just pass it a sheet and URL or file name\n",
    "def download_excel(file,sheet,skiprows):\n",
    "        # download and read in the sheet\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        # download, cache file, and return cached name\n",
    "        file=cache_url(file)\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_excel(file,\n",
    "                       sheet_name=sheet,\n",
    "                       skiprows=skiprows)\n",
    "        except:\n",
    "            print( 'Error: not able to download: ' + file )\n",
    "            \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "488cbaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021: https://www.education.pa.gov/Documents/Teachers-Administrators/School%20Finances/Finances/GFBData/2021-22GFBData.xlsx\n",
      "2020: https://www.education.pa.gov/Documents/Teachers-Administrators/School%20Finances/Finances/GFBData/2020-21GFBData.xlsx\n",
      "2019: https://www.education.pa.gov/Documents/Teachers-Administrators/School%20Finances/Finances/GFBData/2019-20GFBData.xlsx\n",
      "2018: https://www.education.pa.gov/Documents/Teachers-Administrators/School%20Finances/Finances/GFBData/2018-19GFBData.xlsx\n",
      "2017: https://www.education.pa.gov/Documents/Teachers-Administrators/School%20Finances/Finances/GFBData/2017-18GFBData.xlsx\n"
     ]
    }
   ],
   "source": [
    "# builds one giant dataframe\n",
    "df = pd.DataFrame()\n",
    "count=0\n",
    "for l in links: \n",
    "    if count < 5:\n",
    "        # find the start year from the URL\n",
    "        school_year = re.sub('^https.+(\\d\\d\\d\\d)-\\d\\dGFBData.xlsx$','\\\\1',l)\n",
    "        print( school_year + \": \" + l )\n",
    "\n",
    "        # download and read in the sheet\n",
    "        if int(school_year) >= 2011:\n",
    "            df1 = download_excel(l,'ExpDetail', 0)\n",
    "            \n",
    "        # make long form\n",
    "        df1 = pd.melt(df1, id_vars=['InstCat', 'AUN', 'InstName', 'CountyName'],\n",
    "                var_name='expense_category', value_name='expense_value')\n",
    "            \n",
    "        # add in school year\n",
    "        df1['school_year'] = school_year\n",
    "                \n",
    "        # concat the newly downloaded df onto the larger one\n",
    "        df = pd.concat([df, df1],\n",
    "                       ignore_index=True,)\n",
    "    count = count + 1\n",
    "\n",
    "# convert header names to strings\n",
    "df.columns = df.columns.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bcfcb591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick better names\n",
    "df.columns = [column.strip().replace(' ', '_').lower() for column in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb00e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the expense categories & join with the main dataframe\n",
    "expense_category = pd.read_csv( '../lookup_data/expense_lookups.csv' )\n",
    "df = df.join(expense_category.set_index('raw_category'), on='expense_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5647e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop few columns we don't need in the database\n",
    "drop_columns=['instname', 'countyname', 'instcat']\n",
    "df.drop(drop_columns, axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64c378b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data out for another script to consume\n",
    "df.to_pickle(\"../data/budget_expense.pkl.bz2\", compression='infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be97920a",
   "metadata": {},
   "source": [
    "## Below this will be putting summarized tables into sqlite3 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ce6a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DB file\n",
    "cnx = db.connect('../data/pde.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfdc9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lea_info table -> using most recent information about aun so to normalize throughout years\n",
    "expense_info = df.sort_values(by = 'school_year', ascending = False)  # sort by school_year newest first. will grab most recent entry\n",
    "expense_info = expense_info.set_index(['aun', 'school_year', 'expense_category'])\n",
    "expense_info.to_sql(name='finance_expense', con=cnx, if_exists='replace', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
